{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[35]:\n",
    "\n",
    "\n",
    "import time\n",
    "import sys\n",
    "sys.path.insert(0, '../../../Utilities/')\n",
    "from plotting import newfig, savefig\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import numpy as np\n",
    "import operator\n",
    "import itertools\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import *\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "n_jobs = 1\n",
    "trial  = 1\n",
    "\n",
    "# Import database\n",
    "dataset=np.loadtxt(\"../../data/dataset_lite.csv\", delimiter=\",\")\n",
    "x=dataset[:,0:2]\n",
    "y=dataset[:,2] # 0: X, 1: T, 2: shear, 3: bulk, 4: conductivity\n",
    "\n",
    "# Plot dataset\n",
    "#plt.scatter(x[:,1], dataset[:,2], s=0.5)\n",
    "#plt.title('Shear viscosity')\n",
    "#plt.xlabel('T [K]')\n",
    "#plt.ylabel(r'$\\eta$')\n",
    "#plt.show()\n",
    "\n",
    "#plt.scatter(x[:,1], dataset[:,3], s=0.5)\n",
    "#plt.title('Bulk viscosity')\n",
    "#plt.xlabel('T [K]')\n",
    "#plt.ylabel(r'$\\zeta$')\n",
    "#plt.show()\n",
    "\n",
    "#plt.scatter(x[:,1], dataset[:,4], s=0.5)\n",
    "#plt.title('Thermal conductivity')\n",
    "#plt.xlabel('T [K]')\n",
    "#plt.ylabel(r'$\\lambda$')\n",
    "#plt.show()\n",
    "\n",
    "y=np.reshape(y, (-1,1))\n",
    "sc_x = StandardScaler()\n",
    "sc_y = StandardScaler()\n",
    "X = sc_x.fit_transform(x)\n",
    "Y = sc_y.fit_transform(y)\n",
    "\n",
    "# The data is then split into training and test data\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, train_size=0.75, test_size=0.25, random_state=42)\n",
    "\n",
    "print('Training Features Shape:', x_train.shape)\n",
    "print('Training Labels Shape:', y_train.shape)\n",
    "print('Testing Features Shape:', x_test.shape)\n",
    "print('Testing Labels Shape:', y_test.shape)\n",
    "\n",
    "\n",
    "# In[36]:\n",
    "\n",
    "\n",
    "### KR ###\n",
    "\n",
    "from sklearn import kernel_ridge\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "\n",
    "hyper_params = [{'kernel': ('poly','rbf',), 'alpha': (1e-4,1e-2,0.1,1,10,), 'gamma': (0.01,0.1,1,10,100,),}]\n",
    "est=kernel_ridge.KernelRidge()\n",
    "kr = GridSearchCV(est, cv=5, param_grid=hyper_params, verbose=2, n_jobs=n_jobs, scoring='r2')\n",
    "\n",
    "# Train\n",
    "t0 = time.time()\n",
    "kr.fit(x_train, y_train.ravel())\n",
    "kr_fit = time.time() - t0\n",
    "print(\"KR complexity and bandwidth selected and model fitted in %.6f s\" % kr_fit)\n",
    "\n",
    "# Predict\n",
    "#t0 = time.time()\n",
    "#y_kr = kr.predict(x_test)\n",
    "#kr_predict = time.time() - t0\n",
    "#print(\"KR prediction for %d inputs in %.6f s\" % (x_test.shape[0], kr_predict))\n",
    "\n",
    "#print('Mean Absolute Error (MAE):', metrics.mean_absolute_error(y_test, y_kr))\n",
    "#print('Mean Squared Error (MSE):', metrics.mean_squared_error(y_test, y_kr))\n",
    "#print('Root Mean Squared Error (RMSE):', np.sqrt(metrics.mean_squared_error(y_test, y_kr)))\n",
    "\n",
    "train_score_mse = mean_squared_error(      sc_y.inverse_transform(y_train), sc_y.inverse_transform(kr.predict(x_train)))\n",
    "train_score_mae = mean_absolute_error(     sc_y.inverse_transform(y_train), sc_y.inverse_transform(kr.predict(x_train)))\n",
    "train_score_evs = explained_variance_score(sc_y.inverse_transform(y_train), sc_y.inverse_transform(kr.predict(x_train)))\n",
    "train_score_me  = max_error(               sc_y.inverse_transform(y_train), sc_y.inverse_transform(kr.predict(x_train)))\n",
    "\n",
    "test_score_mse  = mean_squared_error(      sc_y.inverse_transform(y_test),  sc_y.inverse_transform(kr.predict(x_test)))\n",
    "test_score_mae  = mean_absolute_error(     sc_y.inverse_transform(y_test),  sc_y.inverse_transform(kr.predict(x_test)))\n",
    "test_score_evs  = explained_variance_score(sc_y.inverse_transform(y_test),  sc_y.inverse_transform(kr.predict(x_test)))\n",
    "test_score_me   = max_error(               sc_y.inverse_transform(y_test),  sc_y.inverse_transform(kr.predict(x_test)))\n",
    "\n",
    "sorted_grid_params = sorted(kr.best_params_.items(), key=operator.itemgetter(0))\n",
    "\n",
    "out_text = '\\t'.join(['kernel-ridge',\n",
    "                      str(trial),\n",
    "                      str(sorted_grid_params).replace('\\n',','),\n",
    "                      str(train_score_mse),\n",
    "                      str(train_score_mae),\n",
    "                      str(train_score_evs),\n",
    "                      str(train_score_me),\n",
    "                      str(test_score_mse),\n",
    "                      str(test_score_mae),\n",
    "                      str(test_score_evs),\n",
    "                      str(test_score_me),\n",
    "                      str(kr_fit)])\n",
    "print(out_text)\n",
    "sys.stdout.flush()\n",
    "\n",
    "best_kernel = kr.best_params_['kernel']\n",
    "best_alpha  = kr.best_params_['alpha']\n",
    "best_gamma  = kr.best_params_['gamma']\n",
    "\n",
    "outF = open(\"KR.txt\", \"w\")\n",
    "print('best_kernel = ', best_kernel, file=outF)\n",
    "print('best_alpha = ',  best_alpha,  file=outF)\n",
    "print('best_gamma = ',  best_gamma,  file=outF)\n",
    "outF.close()\n",
    "\n",
    "kr = KernelRidge(kernel=best_kernel, gamma=best_gamma, alpha=best_alpha)\n",
    "\n",
    "t0 = time.time()\n",
    "kr.fit(x_train, y_train.ravel())\n",
    "kr_fit = time.time() - t0\n",
    "print(\"KR complexity and bandwidth selected and model fitted in %.6f s\" % kr_fit)\n",
    "\n",
    "t0 = time.time()\n",
    "y_kr = kr.predict(x_test)\n",
    "kr_predict = time.time() - t0\n",
    "print(\"KR prediction for %d inputs in %.6f s\" % (x_test.shape[0], kr_predict))\n",
    "\n",
    "outF = open(\"KR.txt\", \"a\")\n",
    "print(\"KR complexity and bandwidth selected and model fitted in %.6f s\" % kr_fit, file=outF)\n",
    "print(\"KR prediction for %d inputs in %.6f s\" % (x_test.shape[0], kr_predict),file=outF)\n",
    "print('Mean Absolute Error (MAE):', metrics.mean_absolute_error(y_test, y_kr), file=outF)\n",
    "print('Mean Squared Error (MSE):', metrics.mean_squared_error(y_test, y_kr), file=outF)\n",
    "print('Root Mean Squared Error (RMSE):', np.sqrt(metrics.mean_squared_error(y_test, y_kr)), file=outF)\n",
    "outF.close()\n",
    "\n",
    "print('Mean Absolute Error (MAE):', metrics.mean_absolute_error(y_test, y_kr))\n",
    "print('Mean Squared Error (MSE):', metrics.mean_squared_error(y_test, y_kr))\n",
    "print('Root Mean Squared Error (RMSE):', np.sqrt(metrics.mean_squared_error(y_test, y_kr)))\n",
    "\n",
    "y_kr_dim = sc_y.inverse_transform(y_kr)\n",
    "\n",
    "\n",
    "# In[37]:\n",
    "\n",
    "\n",
    "### RF ###\n",
    "\n",
    "from sklearn import ensemble\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "hyper_params = [{'n_estimators': (10, 100, 1000),\n",
    "                 'min_weight_fraction_leaf': (0.0, 0.25, 0.5),\n",
    "                 'max_features': ('sqrt','log2',None),\n",
    "}]\n",
    "\n",
    "est=ensemble.RandomForestRegressor()\n",
    "rf = GridSearchCV(est, cv=5, param_grid=hyper_params, verbose=2, n_jobs=n_jobs, scoring='r2')\n",
    "\n",
    "# Train\n",
    "t0 = time.time()\n",
    "rf.fit(x_train, y_train.ravel())\n",
    "rf_fit = time.time() - t0\n",
    "print(\"RF complexity and bandwidth selected and model fitted in %.6f s\" % rf_fit)\n",
    "\n",
    "# Predict\n",
    "#t0 = time.time()\n",
    "#y_rf = rf.predict(x_test)\n",
    "#rf_predict = time.time() - t0\n",
    "#print(\"RF prediction for %d inputs in %.3f s\" % (x_test.shape[0], rf_predict))\n",
    "\n",
    "#print('Mean Absolute Error (MAE):', metrics.mean_absolute_error(y_test, y_rf))\n",
    "#print('Mean Squared Error (MSE):', metrics.mean_squared_error(y_test, y_rf))\n",
    "#print('Root Mean Squared Error (RMSE):', np.sqrt(metrics.mean_squared_error(y_test, y_rf)))\n",
    "\n",
    "train_score_mse = mean_squared_error(      sc_y.inverse_transform(y_train), sc_y.inverse_transform(rf.predict(x_train)))\n",
    "train_score_mae = mean_absolute_error(     sc_y.inverse_transform(y_train), sc_y.inverse_transform(rf.predict(x_train)))\n",
    "train_score_evs = explained_variance_score(sc_y.inverse_transform(y_train), sc_y.inverse_transform(rf.predict(x_train)))\n",
    "train_score_me  = max_error(               sc_y.inverse_transform(y_train), sc_y.inverse_transform(rf.predict(x_train)))\n",
    "\n",
    "test_score_mse  = mean_squared_error(      sc_y.inverse_transform(y_test),  sc_y.inverse_transform(rf.predict(x_test)))\n",
    "test_score_mae  = mean_absolute_error(     sc_y.inverse_transform(y_test),  sc_y.inverse_transform(rf.predict(x_test)))\n",
    "test_score_evs  = explained_variance_score(sc_y.inverse_transform(y_test),  sc_y.inverse_transform(rf.predict(x_test)))\n",
    "test_score_me   = max_error(               sc_y.inverse_transform(y_test),  sc_y.inverse_transform(rf.predict(x_test)))\n",
    "\n",
    "sorted_grid_params = sorted(rf.best_params_.items(), key=operator.itemgetter(0))\n",
    "\n",
    "out_text = '\\t'.join(['random-forest',\n",
    "                      str(trial),\n",
    "                      str(sorted_grid_params).replace('\\n',','),\n",
    "                      str(train_score_mse),\n",
    "                      str(train_score_mae),\n",
    "                      str(train_score_evs),\n",
    "                      str(train_score_me),\n",
    "                      str(test_score_mse),\n",
    "                      str(test_score_mae),\n",
    "                      str(test_score_evs),\n",
    "                      str(test_score_me),\n",
    "                      str(rf_fit)])\n",
    "print(out_text)\n",
    "sys.stdout.flush()\n",
    "\n",
    "best_n_estimators = rf.best_params_['n_estimators']\n",
    "best_min_weight_fraction_leaf = rf.best_params_['min_weight_fraction_leaf']\n",
    "best_max_features = rf.best_params_['max_features']\n",
    "\n",
    "outF = open(\"RF.txt\", \"w\")\n",
    "print('best_n_estimators = ', best_n_estimators, file=outF)\n",
    "print('best_min_weight_fraction_leaf = ', best_min_weight_fraction_leaf, file=outF)\n",
    "print('best_max_features = ', best_max_features, file=outF)\n",
    "outF.close()\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators=best_n_estimators,\n",
    "                           min_weight_fraction_leaf=best_min_weight_fraction_leaf,\n",
    "                           max_features=best_max_features)\n",
    "\n",
    "t0 = time.time()\n",
    "rf.fit(x_train, y_train.ravel())\n",
    "rf_fit = time.time() - t0\n",
    "print(\"RF complexity and bandwidth selected and model fitted in %.6f s\" % rf_fit)\n",
    "\n",
    "t0 = time.time()\n",
    "y_rf = rf.predict(x_test)\n",
    "rf_predict = time.time() - t0\n",
    "print(\"RF prediction for %d inputs in %.6f s\" % (x_test.shape[0], rf_predict))\n",
    "\n",
    "outF = open(\"RF.txt\", \"a\")\n",
    "print(\"RF complexity and bandwidth selected and model fitted in %.6f s\" % rf_fit, file=outF)\n",
    "print(\"RF prediction for %d inputs in %.6f s\" % (x_test.shape[0], rf_predict),file=outF)\n",
    "print('Mean Absolute Error (MAE):', metrics.mean_absolute_error(y_test, y_rf), file=outF)\n",
    "print('Mean Squared Error (MSE):', metrics.mean_squared_error(y_test, y_rf), file=outF)\n",
    "print('Root Mean Squared Error (RMSE):', np.sqrt(metrics.mean_squared_error(y_test, y_rf)), file=outF)\n",
    "outF.close()\n",
    "\n",
    "print('Mean Absolute Error (MAE):', metrics.mean_absolute_error(y_test, y_rf))\n",
    "print('Mean Squared Error (MSE):', metrics.mean_squared_error(y_test, y_rf))\n",
    "print('Root Mean Squared Error (RMSE):', np.sqrt(metrics.mean_squared_error(y_test, y_rf)))\n",
    "\n",
    "y_rf_dim = sc_y.inverse_transform(y_rf)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "### kNN ###\n",
    "\n",
    "from sklearn import neighbors\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neighbors import RadiusNeighborsRegressor\n",
    "\n",
    "hyper_params = [{'algorithm': ('ball_tree', 'kd_tree', 'brute',), 'n_neighbors': (1,2,3,4,5,6,7,8,9,10,),\n",
    "                 'leaf_size': (1, 10, 20, 30, 100,), 'weights': ('uniform', 'distance',), 'p': (1,2,),}]\n",
    "\n",
    "est=neighbors.KNeighborsRegressor()\n",
    "kn = GridSearchCV(est, cv=5, param_grid=hyper_params, verbose=2, n_jobs=n_jobs, scoring='r2')\n",
    "\n",
    "# Train\n",
    "t0 = time.time()\n",
    "kn.fit(x_train, y_train.ravel())\n",
    "kn_fit = time.time() - t0\n",
    "print(\"KN complexity and bandwidth selected and model fitted in %.6f s\" % kn_fit)\n",
    "\n",
    "# Predict\n",
    "#t0 = time.time()\n",
    "#y_kn = kn.predict(x_test)\n",
    "#kn_predict = time.time() - t0\n",
    "#print(\"KN prediction for %d inputs in %.6f s\" % (x_test.shape[0], kn_predict))\n",
    "\n",
    "#print('Mean Absolute Error (MAE):', metrics.mean_absolute_error(y_test, y_kn))\n",
    "#print('Mean Squared Error (MSE):', metrics.mean_squared_error(y_test, y_kn))\n",
    "#print('Root Mean Squared Error (RMSE):', np.sqrt(metrics.mean_squared_error(y_test, y_kn)))\n",
    "\n",
    "train_score_mse = mean_squared_error(      sc_y.inverse_transform(y_train), sc_y.inverse_transform(kn.predict(x_train)))\n",
    "train_score_mae = mean_absolute_error(     sc_y.inverse_transform(y_train), sc_y.inverse_transform(kn.predict(x_train)))\n",
    "train_score_evs = explained_variance_score(sc_y.inverse_transform(y_train), sc_y.inverse_transform(kn.predict(x_train)))\n",
    "train_score_me  = max_error(               sc_y.inverse_transform(y_train), sc_y.inverse_transform(kn.predict(x_train)))\n",
    "\n",
    "test_score_mse  = mean_squared_error(      sc_y.inverse_transform(y_test),  sc_y.inverse_transform(kn.predict(x_test)))\n",
    "test_score_mae  = mean_absolute_error(     sc_y.inverse_transform(y_test),  sc_y.inverse_transform(kn.predict(x_test)))\n",
    "test_score_evs  = explained_variance_score(sc_y.inverse_transform(y_test),  sc_y.inverse_transform(kn.predict(x_test)))\n",
    "test_score_me   = max_error(               sc_y.inverse_transform(y_test),  sc_y.inverse_transform(kn.predict(x_test)))\n",
    "\n",
    "sorted_grid_params = sorted(kn.best_params_.items(), key=operator.itemgetter(0))\n",
    "\n",
    "out_text = '\\t'.join(['k-nearest-neighbour',\n",
    "                      str(trial),\n",
    "                      str(sorted_grid_params).replace('\\n',','),\n",
    "                      str(train_score_mse),\n",
    "                      str(train_score_mae),\n",
    "                      str(train_score_evs),\n",
    "                      str(train_score_me),\n",
    "                      str(test_score_mse),\n",
    "                      str(test_score_mae),\n",
    "                      str(test_score_evs),\n",
    "                      str(test_score_me),\n",
    "                      str(kn_fit)])\n",
    "print(out_text)\n",
    "sys.stdout.flush()\n",
    "\n",
    "best_algorithm = kn.best_params_['algorithm']\n",
    "best_n_neighbors = kn.best_params_['n_neighbors']\n",
    "best_leaf_size = kn.best_params_['leaf_size']\n",
    "best_weights = kn.best_params_['weights']\n",
    "best_p = kn.best_params_['p']\n",
    "\n",
    "outF = open(\"KN.txt\", \"w\")\n",
    "print('best_algorithm = ', best_algorithm, file=outF)\n",
    "print('best_n_neighbors = ', best_n_neighbors, file=outF)\n",
    "print('best_leaf_size = ', best_leaf_size, file=outF)\n",
    "print('best_weights = ', best_weights, file=outF)\n",
    "print('best_p = ', best_p, file=outF)\n",
    "outF.close()\n",
    "\n",
    "kn = KNeighborsRegressor(n_neighbors=best_n_neighbors, algorithm=best_algorithm,\n",
    "                         leaf_size=best_leaf_size, weights=best_weights, p=best_p)\n",
    "\n",
    "t0 = time.time()\n",
    "kn.fit(x_train, y_train.ravel())\n",
    "kn_fit = time.time() - t0\n",
    "print(\"kNN complexity and bandwidth selected and model fitted in %.6f s\" % kn_fit)\n",
    "\n",
    "t0 = time.time()\n",
    "y_kn = kn.predict(x_test)\n",
    "kn_predict = time.time() - t0\n",
    "print(\"KN prediction for %d inputs in %.6f s\" % (x_test.shape[0], kn_predict))\n",
    "\n",
    "outF = open(\"KN.txt\", \"a\")\n",
    "print(\"kNN complexity and bandwidth selected and model fitted in %.6f s\" % kn_fit, file=outF)\n",
    "print(\"kNN prediction for %d inputs in %.6f s\" % (x_test.shape[0], kn_predict),file=outF)\n",
    "print('Mean Absolute Error (MAE):', metrics.mean_absolute_error(y_test, y_kn), file=outF)\n",
    "print('Mean Squared Error (MSE):', metrics.mean_squared_error(y_test, y_kn), file=outF)\n",
    "print('Root Mean Squared Error (RMSE):', np.sqrt(metrics.mean_squared_error(y_test, y_kn)), file=outF)\n",
    "outF.close()\n",
    "\n",
    "print('Mean Absolute Error (MAE):', metrics.mean_absolute_error(y_test, y_kn))\n",
    "print('Mean Squared Error (MSE):', metrics.mean_squared_error(y_test, y_kn))\n",
    "print('Root Mean Squared Error (RMSE):', np.sqrt(metrics.mean_squared_error(y_test, y_kn)))\n",
    "\n",
    "y_kn_dim = sc_y.inverse_transform(y_kn)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "### SVR ###\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "hyper_params = [{'kernel': ('poly', 'rbf',), 'gamma': ('scale', 'auto',),\n",
    "                 'C': (1e-1, 1e0, 1e1,), 'epsilon': (1e-1, 1e0, 1e1,), }]\n",
    "\n",
    "est=svm.SVR()\n",
    "svr = GridSearchCV(est, cv=5, param_grid=hyper_params, verbose=2, n_jobs=n_jobs, scoring='r2')\n",
    "\n",
    "# Train\n",
    "t0 = time.time()\n",
    "svr.fit(x_train, y_train.ravel())\n",
    "svr_fit = time.time() - t0\n",
    "print(\"SVR complexity and bandwidth selected and model fitted in %.6f s\" % svr_fit)\n",
    "\n",
    "# Predict\n",
    "#t0 = time.time()\n",
    "#y_svr = svr.predict(x_test)\n",
    "#svr_predict = time.time() - t0\n",
    "#print(\"SVR prediction for %d inputs in %.6f s\" % (x_test.shape[0], svr_predict))\n",
    "\n",
    "train_score_mse = mean_squared_error(      sc_y.inverse_transform(y_train), sc_y.inverse_transform(svr.predict(x_train)))\n",
    "train_score_mae = mean_absolute_error(     sc_y.inverse_transform(y_train), sc_y.inverse_transform(svr.predict(x_train)))\n",
    "train_score_evs = explained_variance_score(sc_y.inverse_transform(y_train), sc_y.inverse_transform(svr.predict(x_train)))\n",
    "train_score_me  = max_error(               sc_y.inverse_transform(y_train), sc_y.inverse_transform(svr.predict(x_train)))\n",
    "\n",
    "test_score_mse  = mean_squared_error(      sc_y.inverse_transform(y_test),  sc_y.inverse_transform(svr.predict(x_test)))\n",
    "test_score_mae  = mean_absolute_error(     sc_y.inverse_transform(y_test),  sc_y.inverse_transform(svr.predict(x_test)))\n",
    "test_score_evs  = explained_variance_score(sc_y.inverse_transform(y_test),  sc_y.inverse_transform(svr.predict(x_test)))\n",
    "test_score_me   = max_error(               sc_y.inverse_transform(y_test),  sc_y.inverse_transform(svr.predict(x_test)))\n",
    "\n",
    "sorted_grid_params = sorted(svr.best_params_.items(), key=operator.itemgetter(0))\n",
    "\n",
    "out_text = '\\t'.join(['svr',\n",
    "                      str(trial),\n",
    "                      str(sorted_grid_params).replace('\\n',','),\n",
    "                      str(train_score_mse),\n",
    "                      str(train_score_mae),\n",
    "                      str(train_score_evs),\n",
    "                      str(train_score_me),\n",
    "                      str(test_score_mse),\n",
    "                      str(test_score_mae),\n",
    "                      str(test_score_evs),\n",
    "                      str(test_score_me),\n",
    "                      str(svr_fit)])\n",
    "print(out_text)\n",
    "sys.stdout.flush()\n",
    "\n",
    "best_kernel = svr.best_params_['kernel']\n",
    "best_gamma = svr.best_params_['gamma']\n",
    "best_C = svr.best_params_['C']\n",
    "best_epsilon = svr.best_params_['epsilon']\n",
    "#best_coef0 = svr.best_params_['coef0']\n",
    "\n",
    "outF = open(\"SVR.txt\", \"w\")\n",
    "print('best_kernel = ', best_kernel, file=outF)\n",
    "print('best_gamma = ', best_gamma, file=outF)\n",
    "print('best_C = ', best_C, file=outF)\n",
    "print('best_epsilon = ', best_epsilon, file=outF)\n",
    "#print('best_coef0 = ', best_coef0, file=outF)\n",
    "outF.close()\n",
    "\n",
    "svr = SVR(kernel=best_kernel, epsilon=best_epsilon, C=best_C, gamma=best_gamma)\n",
    "\n",
    "t0 = time.time()\n",
    "svr.fit(x_train, y_train.ravel())\n",
    "svr_fit = time.time() - t0\n",
    "print(\"SVR complexity and bandwidth selected and model fitted in %.6f s\" % svr_fit)\n",
    "\n",
    "t0 = time.time()\n",
    "y_svr = svr.predict(x_test)\n",
    "svr_predict = time.time() - t0\n",
    "print(\"SVR prediction for %d inputs in %.6f s\" % (x_test.shape[0], svr_predict))\n",
    "\n",
    "outF = open(\"SVR.txt\", \"a\")\n",
    "print(\"SVR complexity and bandwidth selected and model fitted in %.6f s\" % svr_fit, file=outF)\n",
    "print(\"SVR prediction for %d inputs in %.6f s\" % (x_test.shape[0], svr_predict),file=outF)\n",
    "print('Mean Absolute Error (MAE):', metrics.mean_absolute_error(y_test, y_svr), file=outF)\n",
    "print('Mean Squared Error (MSE):', metrics.mean_squared_error(y_test, y_svr), file=outF)\n",
    "print('Root Mean Squared Error (RMSE):', np.sqrt(metrics.mean_squared_error(y_test, y_svr)), file=outF)\n",
    "outF.close()\n",
    "\n",
    "print('Mean Absolute Error (MAE):', metrics.mean_absolute_error(y_test, y_svr))\n",
    "print('Mean Squared Error (MSE):', metrics.mean_squared_error(y_test, y_svr))\n",
    "print('Root Mean Squared Error (RMSE):', np.sqrt(metrics.mean_squared_error(y_test, y_svr)))\n",
    "\n",
    "y_svr_dim = sc_y.inverse_transform(y_svr)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "### MLP\n",
    "\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "hyper_params = [\n",
    "    {\n",
    "        'activation' : ('logistic', 'tanh', 'relu',),\n",
    "        'solver' : ('lbfgs','adam','sgd',),\n",
    "        'learning_rate' : ('constant', 'invscaling', 'adaptive',),\n",
    "        #'hidden_layer_sizes': [(50, 50), (100,100), (150,150), (200,200),],\n",
    "        #'early_stopping': (True, False),\n",
    "    },\n",
    "]\n",
    "\n",
    "est=MLPRegressor()\n",
    "mlp = GridSearchCV(est, cv=5, param_grid=hyper_params, verbose=2, n_jobs=n_jobs, scoring='r2')\n",
    "\n",
    "# Train\n",
    "t0 = time.time()\n",
    "mlp.fit(x_train, y_train.ravel())\n",
    "mlp_fit = time.time() - t0\n",
    "print(\"MLP complexity and bandwidth selected and model fitted in %.6f s\" % mlp_fit)\n",
    "\n",
    "# Predict\n",
    "#t0 = time.time()\n",
    "#y_mlp = svr.predict(x_test)\n",
    "#mlp_predict = time.time() - t0\n",
    "#print(\"MLP prediction for %d inputs in %.6f s\" % (x_test.shape[0], mlp_predict))\n",
    "\n",
    "train_score_mse = mean_squared_error(      sc_y.inverse_transform(y_train), sc_y.inverse_transform(mlp.predict(x_train)))\n",
    "train_score_mae = mean_absolute_error(     sc_y.inverse_transform(y_train), sc_y.inverse_transform(mlp.predict(x_train)))\n",
    "train_score_evs = explained_variance_score(sc_y.inverse_transform(y_train), sc_y.inverse_transform(mlp.predict(x_train)))\n",
    "train_score_me  = max_error(               sc_y.inverse_transform(y_train), sc_y.inverse_transform(mlp.predict(x_train)))\n",
    "\n",
    "test_score_mse  = mean_squared_error(      sc_y.inverse_transform(y_test),  sc_y.inverse_transform(mlp.predict(x_test)))\n",
    "test_score_mae  = mean_absolute_error(     sc_y.inverse_transform(y_test),  sc_y.inverse_transform(mlp.predict(x_test)))\n",
    "test_score_evs  = explained_variance_score(sc_y.inverse_transform(y_test),  sc_y.inverse_transform(mlp.predict(x_test)))\n",
    "test_score_me   = max_error(               sc_y.inverse_transform(y_test),  sc_y.inverse_transform(mlp.predict(x_test)))\n",
    "\n",
    "sorted_grid_params = sorted(mlp.best_params_.items(), key=operator.itemgetter(0))\n",
    "\n",
    "out_text = '\\t'.join(['mlp',\n",
    "                      str(trial),\n",
    "                      str(sorted_grid_params).replace('\\n',','),\n",
    "                      str(train_score_mse),\n",
    "                      str(train_score_mae),\n",
    "                      str(train_score_evs),\n",
    "                      str(train_score_me),\n",
    "                      str(test_score_mse),\n",
    "                      str(test_score_mae),\n",
    "                      str(test_score_evs),\n",
    "                      str(test_score_me),\n",
    "                      str(mlp_fit)])\n",
    "print(out_text)\n",
    "sys.stdout.flush()\n",
    "\n",
    "best_activation = mlp.best_params_['activation']\n",
    "best_solver = mlp.best_params_['solver']\n",
    "best_learning_rate = mlp.best_params_['learning_rate']\n",
    "\n",
    "outF = open(\"MLP.txt\", \"w\")\n",
    "print('best_activation = ', best_activation, file=outF)\n",
    "print('best_solver = ', best_solver, file=outF)\n",
    "print('best_learning_rate = ', best_learning_rate, file=outF)\n",
    "outF.close()\n",
    "\n",
    "mlp = MLPRegressor(activation=best_activation, solver=best_solver, learning_rate=best_learning_rate)\n",
    "\n",
    "t0 = time.time()\n",
    "mlp.fit(x_train, y_train.ravel())\n",
    "mlp_fit = time.time() - t0\n",
    "print(\"MLP complexity and bandwidth selected and model fitted in %.6f s\" % mlp_fit)\n",
    "\n",
    "t0 = time.time()\n",
    "y_mlp = mlp.predict(x_test)\n",
    "mlp_predict = time.time() - t0\n",
    "print(\"MLP prediction for %d inputs in %.6f s\" % (x_test.shape[0], mlp_predict))\n",
    "\n",
    "outF = open(\"MLP.txt\", \"a\")\n",
    "print(\"MLP complexity and bandwidth selected and model fitted in %.6f s\" % mlp_fit, file=outF)\n",
    "print(\"MLP prediction for %d inputs in %.6f s\" % (x_test.shape[0], mlp_predict),file=outF)\n",
    "print('Mean Absolute Error (MAE):', metrics.mean_absolute_error(y_test, y_mlp), file=outF)\n",
    "print('Mean Squared Error (MSE):', metrics.mean_squared_error(y_test, y_mlp), file=outF)\n",
    "print('Root Mean Squared Error (RMSE):', np.sqrt(metrics.mean_squared_error(y_test, y_mlp)), file=outF)\n",
    "outF.close()\n",
    "\n",
    "print('Mean Absolute Error (MAE):', metrics.mean_absolute_error(y_test, y_mlp))\n",
    "print('Mean Squared Error (MSE):', metrics.mean_squared_error(y_test, y_mlp))\n",
    "print('Root Mean Squared Error (RMSE):', np.sqrt(metrics.mean_squared_error(y_test, y_mlp)))\n",
    "\n",
    "y_mlp_dim = sc_y.inverse_transform(y_mlp)\n",
    "\n",
    "\n",
    "# In[39]:\n",
    "\n",
    "\n",
    "### GP ###\n",
    "\n",
    "from sklearn import gaussian_process\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import WhiteKernel, ExpSineSquared, DotProduct, RBF, RationalQuadratic, ConstantKernel, Matern\n",
    "\n",
    "hyper_params = [{#'n_restarts_optimizer': (0,1,10,100,),\n",
    "                 #'alpha': (1e-3, 1e-2, 1e-1, 1e0, 1e1, 1e2, 1e3,),\n",
    "                 'kernel': (1.0 * RBF(1.0),\n",
    "                            #ConstantKernel(1.0, (1e-3, 1e3)) * RBF(10, (1e-2, 1e2)),\n",
    "                            #ExpSineSquared(1.0, 5.0, periodicity_bounds=(1e-2, 1e1)),\n",
    "                            #DotProduct() + WhiteKernel(),\n",
    "                            #ConstantKernel(0.1, (0.01, 10.0)) * (DotProduct(sigma_0=1.0, sigma_0_bounds=(0.1, 10.0)) ** 2),\n",
    "                            #1.0 * Matern(length_scale=1.0, length_scale_bounds=(1e-1, 10.0), nu=1.5),\n",
    "                            #1.0 * RationalQuadratic(length_scale=1.0, alpha=0.1),\n",
    "                            #1.0 * RBF(length_scale=1.0, length_scale_bounds=(1e-1, 10.0)),\n",
    "                            #1.0 * ExpSineSquared(length_scale=1.0, periodicity=3.0,\n",
    "                            #                     length_scale_bounds=(0.1, 10.0),\n",
    "                            #                     periodicity_bounds=(1.0, 10.0)),\n",
    "                           ),}]\n",
    "\n",
    "\n",
    "est = gaussian_process.GaussianProcessRegressor()\n",
    "gp = GridSearchCV(est, cv=5, param_grid=hyper_params, verbose=2, n_jobs=n_jobs, scoring='r2')\n",
    "\n",
    "# Train\n",
    "t0 = time.time()\n",
    "gp.fit(x_train, y_train.ravel())\n",
    "gp_fit = time.time() - t0\n",
    "print(\"GP complexity and bandwidth selected and model fitted in %.6f s\" % gp_fit)\n",
    "\n",
    "# Predict\n",
    "#t0 = time.time()\n",
    "#y_mlp = svr.predict(x_test)\n",
    "#mlp_predict = time.time() - t0\n",
    "#print(\"MLP prediction for %d inputs in %.6f s\" % (x_test.shape[0], mlp_predict))\n",
    "\n",
    "train_score_mse = mean_squared_error(      sc_y.inverse_transform(y_train), sc_y.inverse_transform(gp.predict(x_train)))\n",
    "train_score_mae = mean_absolute_error(     sc_y.inverse_transform(y_train), sc_y.inverse_transform(gp.predict(x_train)))\n",
    "train_score_evs = explained_variance_score(sc_y.inverse_transform(y_train), sc_y.inverse_transform(gp.predict(x_train)))\n",
    "train_score_me  = max_error(               sc_y.inverse_transform(y_train), sc_y.inverse_transform(gp.predict(x_train)))\n",
    "\n",
    "test_score_mse  = mean_squared_error(      sc_y.inverse_transform(y_test),  sc_y.inverse_transform(gp.predict(x_test)))\n",
    "test_score_mae  = mean_absolute_error(     sc_y.inverse_transform(y_test),  sc_y.inverse_transform(gp.predict(x_test)))\n",
    "test_score_evs  = explained_variance_score(sc_y.inverse_transform(y_test),  sc_y.inverse_transform(gp.predict(x_test)))\n",
    "test_score_me   = max_error(               sc_y.inverse_transform(y_test),  sc_y.inverse_transform(gp.predict(x_test)))\n",
    "\n",
    "sorted_grid_params = sorted(gp.best_params_.items(), key=operator.itemgetter(0))\n",
    "\n",
    "out_text = '\\t'.join(['gp',\n",
    "                      str(trial),\n",
    "                      str(sorted_grid_params).replace('\\n',','),\n",
    "                      str(train_score_mse),\n",
    "                      str(train_score_mae),\n",
    "                      str(train_score_evs),\n",
    "                      str(train_score_me),\n",
    "                      str(test_score_mse),\n",
    "                      str(test_score_mae),\n",
    "                      str(test_score_evs),\n",
    "                      str(test_score_me),\n",
    "                      str(gp_fit)])\n",
    "print(out_text)\n",
    "sys.stdout.flush()\n",
    "\n",
    "best_kernel = gp.best_params_['kernel']\n",
    "#best_alpha = gp.best_params_['alpha']\n",
    "#best_n_restarts_optimizer = gp.best_params_['n_restarts_optimizer']\n",
    "#best_gamma = gp.best_params_['gamma']\n",
    "#best_C = gp.best_params_['C']\n",
    "#best_epsilon = gp.best_params_['epsilon']\n",
    "\n",
    "outF = open(\"GP.txt\", \"w\")\n",
    "print('best_kernel = ', best_kernel, file=outF)\n",
    "#print('best_alpha = ', best_alpha, file=outF)\n",
    "#print('best_n_restarts_optimizer = ', best_n_restarts_optimizer, file=outF)\n",
    "outF.close()\n",
    "\n",
    "#gp = GaussianProcessRegressor(kernel=best_kernel, alpha=best_alpha, n_restarts_optimizer=best_n_restarts_optimizer)\n",
    "gp = GaussianProcessRegressor(kernel=best_kernel)\n",
    "\n",
    "t0 = time.time()\n",
    "gp.fit(x_train, y_train.ravel())\n",
    "gp_fit = time.time() - t0\n",
    "print(\"GP complexity and bandwidth selected and model fitted in %.6f s\" % gp_fit)\n",
    "\n",
    "t0 = time.time()\n",
    "y_gp = mlp.predict(x_test)\n",
    "gp_predict = time.time() - t0\n",
    "print(\"GP prediction for %d inputs in %.6f s\" % (x_test.shape[0], gp_predict))\n",
    "\n",
    "outF = open(\"GP.txt\", \"a\")\n",
    "print(\"GP complexity and bandwidth selected and model fitted in %.6f s\" % gp_fit, file=outF)\n",
    "print(\"GP prediction for %d inputs in %.6f s\" % (x_test.shape[0], gp_predict),file=outF)\n",
    "print('Mean Absolute Error (MAE):', metrics.mean_absolute_error(y_test, y_gp), file=outF)\n",
    "print('Mean Squared Error (MSE):', metrics.mean_squared_error(y_test, y_gp), file=outF)\n",
    "print('Root Mean Squared Error (RMSE):', np.sqrt(metrics.mean_squared_error(y_test, y_gp)), file=outF)\n",
    "outF.close()\n",
    "\n",
    "print('Mean Absolute Error (MAE):', metrics.mean_absolute_error(y_test, y_gp))\n",
    "print('Mean Squared Error (MSE):', metrics.mean_squared_error(y_test, y_gp))\n",
    "print('Root Mean Squared Error (RMSE):', np.sqrt(metrics.mean_squared_error(y_test, y_gp)))\n",
    "\n",
    "y_gp_dim = sc_y.inverse_transform(y_gp)\n",
    "\n",
    "\n",
    "# In[40]:\n",
    "\n",
    "\n",
    "### Global print\n",
    "\n",
    "x_test_dim = sc_x.inverse_transform(x_test)\n",
    "y_test_dim = sc_y.inverse_transform(y_test)\n",
    "\n",
    "plt.scatter(x_test_dim[:,1], y_test_dim[:], s=5, c='red', marker='o', label='KAPPA')\n",
    "plt.scatter(x_test_dim[:,1], y_svr_dim[:], s=1, facecolors='none', edgecolors='k', marker='p', label='Support Vector Machine')\n",
    "plt.scatter(x_test_dim[:,1], y_kr_dim[:],  s=1, facecolors='none', edgecolors='k', marker='p', label='Kernel Ridge')\n",
    "plt.scatter(x_test_dim[:,1], y_rf_dim[:],  s=1, facecolors='none', edgecolors='k', marker='p', label='Random Forest')\n",
    "plt.scatter(x_test_dim[:,1], y_kn_dim[:],  s=1, facecolors='none', edgecolors='k', marker='p', label='k-Nearest Neighbour')\n",
    "plt.scatter(x_test_dim[:,1], y_mlp_dim[:], s=1, facecolors='none', edgecolors='k', marker='p', label='Multi-layer Perceptron')\n",
    "plt.scatter(x_test_dim[:,1], y_gp_dim[:],  s=1, facecolors='none', edgecolors='k', marker='p', label='Gaussian Process')\n",
    "plt.title('Bulk viscosity regression')\n",
    "plt.ylabel(r'$\\zeta$ [Pa·s]')\n",
    "plt.xlabel('T [K] ')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"zeta.pdf\",     dpi=150, crop='false')\n",
    "#plt.savefig(\"eta_SVR.pdf\", dpi=150, crop='false')\n",
    "#plt.savefig(\"eta_KR.pdf\",  dpi=150, crop='false')\n",
    "#plt.savefig(\"eta_RF.pdf\",  dpi=150, crop='false')\n",
    "#plt.savefig(\"eta_KN.pdf\",  dpi=150, crop='false')\n",
    "#plt.savefig(\"eta_MLP.pdf\", dpi=150, crop='false')\n",
    "#plt.savefig(\"zeta_GP.pdf\", dpi=150, crop='false')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
