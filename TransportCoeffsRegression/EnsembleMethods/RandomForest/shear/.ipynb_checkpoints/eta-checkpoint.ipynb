{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Features Shape: (3300, 2)\n",
      "Training Labels Shape: (3300, 1)\n",
      "Testing Features Shape: (1100, 2)\n",
      "Testing Labels Shape: (1100, 1)\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "import time\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '../../../Utilities/')\n",
    "\n",
    "from plotting import newfig, savefig\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import numpy as np\n",
    "\n",
    "import operator\n",
    "import itertools\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import *\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, learning_curve, cross_val_score\n",
    "\n",
    "from sklearn import kernel_ridge\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "\n",
    "from sklearn import ensemble\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "n_jobs = 1\n",
    "trial  = 1\n",
    "\n",
    "# Import database\n",
    "dataset=np.loadtxt(\"../../data/dataset_lite.csv\", delimiter=\",\")\n",
    "x=dataset[:,0:2]\n",
    "y=dataset[:,2] # 0: X, 1: T, 2: shear, 3: bulk, 4: conductivity\n",
    "\n",
    "# Plot dataset\n",
    "#plt.scatter(x[:,1], dataset[:,2], s=0.5)\n",
    "#plt.title('Shear viscosity')\n",
    "#plt.xlabel('T [K]')\n",
    "#plt.ylabel(r'$\\eta$')\n",
    "#plt.show()\n",
    "\n",
    "y=np.reshape(y, (-1,1))\n",
    "sc_x = StandardScaler()\n",
    "sc_y = StandardScaler()\n",
    "X = sc_x.fit_transform(x)\n",
    "Y = sc_y.fit_transform(y)\n",
    "\n",
    "# The data is then split into training and test data\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, train_size=0.75, test_size=0.25, random_state=42)\n",
    "\n",
    "print('Training Features Shape:', x_train.shape)\n",
    "print('Training Labels Shape:', y_train.shape)\n",
    "print('Testing Features Shape:', x_test.shape)\n",
    "print('Testing Labels Shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV] n_estimators=1 ..................................................\n",
      "[CV] ................................... n_estimators=1, total=   0.0s\n",
      "[CV] n_estimators=1 ..................................................\n",
      "[CV] ................................... n_estimators=1, total=   0.0s\n",
      "[CV] n_estimators=1 ..................................................\n",
      "[CV] ................................... n_estimators=1, total=   0.1s\n",
      "[CV] n_estimators=1 ..................................................\n",
      "[CV] ................................... n_estimators=1, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] n_estimators=1 ..................................................\n",
      "[CV] ................................... n_estimators=1, total=   0.0s\n",
      "[CV] n_estimators=101 ................................................\n",
      "[CV] ................................. n_estimators=101, total=   1.4s\n",
      "[CV] n_estimators=101 ................................................\n",
      "[CV] ................................. n_estimators=101, total=   1.1s\n",
      "[CV] n_estimators=101 ................................................\n",
      "[CV] ................................. n_estimators=101, total=   1.4s\n",
      "[CV] n_estimators=101 ................................................\n",
      "[CV] ................................. n_estimators=101, total=   1.4s\n",
      "[CV] n_estimators=101 ................................................\n",
      "[CV] ................................. n_estimators=101, total=   1.3s\n",
      "[CV] n_estimators=201 ................................................\n",
      "[CV] ................................. n_estimators=201, total=   2.6s\n",
      "[CV] n_estimators=201 ................................................\n",
      "[CV] ................................. n_estimators=201, total=   2.1s\n",
      "[CV] n_estimators=201 ................................................\n",
      "[CV] ................................. n_estimators=201, total=   2.4s\n",
      "[CV] n_estimators=201 ................................................\n",
      "[CV] ................................. n_estimators=201, total=   2.2s\n",
      "[CV] n_estimators=201 ................................................\n",
      "[CV] ................................. n_estimators=201, total=   2.4s\n",
      "[CV] n_estimators=301 ................................................\n",
      "[CV] ................................. n_estimators=301, total=   3.5s\n",
      "[CV] n_estimators=301 ................................................\n",
      "[CV] ................................. n_estimators=301, total=   3.3s\n",
      "[CV] n_estimators=301 ................................................\n",
      "[CV] ................................. n_estimators=301, total=   3.5s\n",
      "[CV] n_estimators=301 ................................................\n",
      "[CV] ................................. n_estimators=301, total=   3.6s\n",
      "[CV] n_estimators=301 ................................................\n",
      "[CV] ................................. n_estimators=301, total=   3.3s\n",
      "[CV] n_estimators=401 ................................................\n",
      "[CV] ................................. n_estimators=401, total=   4.5s\n",
      "[CV] n_estimators=401 ................................................\n",
      "[CV] ................................. n_estimators=401, total=   4.2s\n",
      "[CV] n_estimators=401 ................................................\n",
      "[CV] ................................. n_estimators=401, total=   4.4s\n",
      "[CV] n_estimators=401 ................................................\n",
      "[CV] ................................. n_estimators=401, total=   4.2s\n",
      "[CV] n_estimators=401 ................................................\n",
      "[CV] ................................. n_estimators=401, total=   4.6s\n",
      "[CV] n_estimators=501 ................................................\n",
      "[CV] ................................. n_estimators=501, total=   5.1s\n",
      "[CV] n_estimators=501 ................................................\n",
      "[CV] ................................. n_estimators=501, total=   5.9s\n",
      "[CV] n_estimators=501 ................................................\n",
      "[CV] ................................. n_estimators=501, total=   5.6s\n",
      "[CV] n_estimators=501 ................................................\n",
      "[CV] ................................. n_estimators=501, total=   5.5s\n",
      "[CV] n_estimators=501 ................................................\n",
      "[CV] ................................. n_estimators=501, total=   6.1s\n",
      "[CV] n_estimators=601 ................................................\n",
      "[CV] ................................. n_estimators=601, total=   6.7s\n",
      "[CV] n_estimators=601 ................................................\n",
      "[CV] ................................. n_estimators=601, total=   6.6s\n",
      "[CV] n_estimators=601 ................................................\n",
      "[CV] ................................. n_estimators=601, total=   6.9s\n",
      "[CV] n_estimators=601 ................................................\n",
      "[CV] ................................. n_estimators=601, total=   7.1s\n",
      "[CV] n_estimators=601 ................................................\n",
      "[CV] ................................. n_estimators=601, total=   6.1s\n",
      "[CV] n_estimators=701 ................................................\n",
      "[CV] ................................. n_estimators=701, total=   7.5s\n",
      "[CV] n_estimators=701 ................................................\n",
      "[CV] ................................. n_estimators=701, total=   7.5s\n",
      "[CV] n_estimators=701 ................................................\n",
      "[CV] ................................. n_estimators=701, total=   7.8s\n",
      "[CV] n_estimators=701 ................................................\n",
      "[CV] ................................. n_estimators=701, total=   7.5s\n",
      "[CV] n_estimators=701 ................................................\n",
      "[CV] ................................. n_estimators=701, total=   7.5s\n",
      "[CV] n_estimators=801 ................................................\n",
      "[CV] ................................. n_estimators=801, total=   9.0s\n",
      "[CV] n_estimators=801 ................................................\n",
      "[CV] ................................. n_estimators=801, total=   8.2s\n",
      "[CV] n_estimators=801 ................................................\n",
      "[CV] ................................. n_estimators=801, total=   8.1s\n",
      "[CV] n_estimators=801 ................................................\n",
      "[CV] ................................. n_estimators=801, total=   8.8s\n",
      "[CV] n_estimators=801 ................................................\n",
      "[CV] ................................. n_estimators=801, total=   9.0s\n",
      "[CV] n_estimators=901 ................................................\n",
      "[CV] ................................. n_estimators=901, total=   9.9s\n",
      "[CV] n_estimators=901 ................................................\n",
      "[CV] ................................. n_estimators=901, total=  10.1s\n",
      "[CV] n_estimators=901 ................................................\n",
      "[CV] ................................. n_estimators=901, total=   9.9s\n",
      "[CV] n_estimators=901 ................................................\n",
      "[CV] ................................. n_estimators=901, total=   9.8s\n",
      "[CV] n_estimators=901 ................................................\n",
      "[CV] ................................. n_estimators=901, total=   9.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:  4.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF complexity and bandwidth selected and model fitted in 286.063 s\n"
     ]
    }
   ],
   "source": [
    "hyper_params = [{'n_estimators': (1,10,100,1000,),\n",
    "                 'min_weight_fraction_leaf': (0.0, 0.25, 0.5),\n",
    "                 'max_features': ('sqrt','log2',None),\n",
    "}]\n",
    "\n",
    "# https://scikit-learn.org/stable/modules/model_evaluation.html#regression-metrics\n",
    "\n",
    "# The scorers can be either be one of the predefined metric strings or a scorer\n",
    "# callable, like the one returned by make_scorer\n",
    "scoring = {'EV': 'explained_variance',\n",
    "           'ME': 'max_error',\n",
    "           'NMAE': 'neg_mean_absolute_error',\n",
    "           'NMSE': 'neg_mean_squared_error',\n",
    "           'NRMSE': 'neg_root_mean_squared_error',\n",
    "#          'NMSLE':'neg_mean_squared_log_error',\n",
    "           'NMAE': 'neg_median_absolute_error',\n",
    "           'R2':'r2',\n",
    "#          'NMPD': 'neg_mean_poisson_deviance',\n",
    "#          'NMGD':'neg_mean_gamma_deviance'\n",
    "          }\n",
    "\n",
    "#est=ensemble.RandomForestRegressor()\n",
    "#grid_clf = GridSearchCV(est, cv=5, param_grid=hyper_params, verbose=2, n_jobs=n_jobs, scoring='r2')\n",
    "#grid_clf = GridSearchCV(est, cv=5, param_grid=hyper_params, verbose=2, n_jobs=n_jobs, \n",
    "#                        scoring=scoring, refit='r2', return_train_score=True)\n",
    "\n",
    "grid_clf = GridSearchCV(RandomForestRegressor(random_state=42),\n",
    "                  #param_grid={'min_samples_split': range(2, 403, 10)},\n",
    "                  param_grid={'n_estimators': range(1,1000, 100)},\n",
    "                  scoring=scoring, refit='R2', return_train_score=True,\n",
    "                  verbose=2, n_jobs=n_jobs)\n",
    "\n",
    "t0 = time.time()\n",
    "grid_clf.fit(x_train, y_train.ravel())\n",
    "runtime = time.time() - t0\n",
    "print(\"RF complexity and bandwidth selected and model fitted in %.3f s\" % runtime)\n",
    "\n",
    "results = grid_clf.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "1.233585602316465e-07",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-a6facbca41c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_score_mae\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# https://scikit-learn.org/stable/auto_examples/model_selection/plot_multi_metric_evaluation.html\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 1.233585602316465e-07"
     ]
    }
   ],
   "source": [
    "\n",
    "print(grid_clf.cv_results_[train_score_mae])\n",
    "\n",
    "# https://scikit-learn.org/stable/auto_examples/model_selection/plot_multi_metric_evaluation.html\n",
    "\n",
    "plt.figure(figsize=(13, 13))\n",
    "plt.title(\"GridSearchCV evaluating using multiple scorers simultaneously\",\n",
    "          fontsize=16)\n",
    "\n",
    "#plt.xlabel(\"min samples split\")\n",
    "plt.xlabel(\"n estimators\")\n",
    "plt.ylabel(\"Score\")\n",
    "\n",
    "ax = plt.gca()\n",
    "#ax.set_xlim(0, 402)\n",
    "#ax.set_ylim(0.73, 1)\n",
    "\n",
    "# Get the regular numpy array from the MaskedArray\n",
    "#X_axis = np.array(results['param_min_samples_split'].data, dtype=float)\n",
    "X_axis = np.array(results['param_n_estimators'].data, dtype=float)\n",
    "\n",
    "for scorer, color in zip(sorted(scoring), ['g', 'k', 'r', 'b', 'y', 'm']):\n",
    "    for sample, style in (('train', '--'), ('test', '-')):\n",
    "        sample_score_mean = results['mean_%s_%s' % (sample, scorer)]\n",
    "        sample_score_std = results['std_%s_%s' % (sample, scorer)]\n",
    "        ax.fill_between(X_axis, sample_score_mean - sample_score_std,\n",
    "                        sample_score_mean + sample_score_std,\n",
    "                        alpha=0.1 if sample == 'test' else 0, color=color)\n",
    "        ax.plot(X_axis, sample_score_mean, style, color=color,\n",
    "                alpha=1 if sample == 'test' else 0.7,\n",
    "                label=\"%s (%s)\" % (scorer, sample))\n",
    "\n",
    "    best_index = np.nonzero(results['rank_test_%s' % scorer] == 1)[0][0]\n",
    "    best_score = results['mean_test_%s' % scorer][best_index]\n",
    "\n",
    "    # Plot a dotted vertical line at the best score for that scorer marked by x\n",
    "    ax.plot([X_axis[best_index], ] * 2, [0, best_score], \n",
    "            linestyle='-.', color=color, marker='x', markeredgewidth=3, ms=8)\n",
    "\n",
    "    # Annotate the best score for that scorer\n",
    "    ax.annotate(\"%0.2f\" % best_score, (X_axis[best_index], best_score + 0.005))\n",
    "\n",
    "plt.legend(loc=\"best\")\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.4062383273762887e-07\n"
     ]
    }
   ],
   "source": [
    "train_score_mse  = mean_squared_error(sc_y.inverse_transform(y_train), sc_y.inverse_transform(grid_clf.predict(x_train)))\n",
    "train_score_mae  = mean_absolute_error(sc_y.inverse_transform(y_train),sc_y.inverse_transform(grid_clf.predict(x_train)))\n",
    "train_score_evs  = explained_variance_score(sc_y.inverse_transform(y_train), sc_y.inverse_transform(grid_clf.predict(x_train)))\n",
    "train_score_me   = max_error(sc_y.inverse_transform(y_train), sc_y.inverse_transform(grid_clf.predict(x_train)))\n",
    "\n",
    "test_score_mse  = mean_squared_error(sc_y.inverse_transform(y_test), sc_y.inverse_transform(grid_clf.predict(x_test)))\n",
    "test_score_mae  = mean_absolute_error(sc_y.inverse_transform(y_test), sc_y.inverse_transform(grid_clf.predict(x_test)))\n",
    "test_score_evs  = explained_variance_score(sc_y.inverse_transform(y_test), sc_y.inverse_transform(grid_clf.predict(x_test)))\n",
    "test_score_me   = max_error(sc_y.inverse_transform(y_test), sc_y.inverse_transform(grid_clf.predict(x_test)))\n",
    "\n",
    "print(test_score_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_grid_params = sorted(grid_clf.best_params_.items(), key=operator.itemgetter(0))\n",
    "\n",
    "out_text = '\\t'.join(['random-forest',\n",
    "                      str(trial),\n",
    "                      str(sorted_grid_params).replace('\\n',','),\n",
    "                      str(train_score_mse),\n",
    "                      str(train_score_mae),\n",
    "                      str(train_score_evs),\n",
    "                      str(train_score_me),\n",
    "                      str(test_score_mse),\n",
    "                      str(test_score_mae),\n",
    "                      str(test_score_evs),\n",
    "                      str(test_score_me),\n",
    "                      str(runtime)])\n",
    "print(out_text)\n",
    "sys.stdout.flush()\n",
    "\n",
    "best_n_estimators = grid_clf.best_params_['n_estimators']\n",
    "best_min_weight_fraction_leaf = grid_clf.best_params_['min_weight_fraction_leaf']\n",
    "best_max_features = grid_clf.best_params_['max_features']\n",
    "\n",
    "# open a (new) file to write\n",
    "outF = open(\"output.txt\", \"w\")\n",
    "print('best_n_estimators = ', best_n_estimators, file=outF)\n",
    "print('best_min_weight_fraction_leaf = ', best_min_weight_fraction_leaf, file=outF)\n",
    "print('best_max_features = ', best_max_features, file=outF)\n",
    "outF.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(n_estimators=best_n_estimators,\n",
    "                           min_weight_fraction_leaf=best_min_weight_fraction_leaf,\n",
    "                           max_features=best_max_features)\n",
    "\n",
    "t0 = time.time()\n",
    "rf.fit(x_train, y_train.ravel())\n",
    "rf_fit = time.time() - t0\n",
    "print(\"RF complexity and bandwidth selected and model fitted in %.3f s\" % rf_fit)\n",
    "\n",
    "t0 = time.time()\n",
    "y_rf = rf.predict(x_test)\n",
    "rf_predict = time.time() - t0\n",
    "print(\"KR prediction for %d inputs in %.3f s\" % (x_test.shape[0], rf_predict))\n",
    "\n",
    "# open a file to append\n",
    "outF = open(\"output.txt\", \"a\")\n",
    "print(\"RF complexity and bandwidth selected and model fitted in %.3f s\" % rf_fit, file=outF)\n",
    "print(\"RF prediction for %d inputs in %.3f s\" % (x_test.shape[0], rf_predict),file=outF)\n",
    "print('Mean Absolute Error (MAE):', metrics.mean_absolute_error(y_test, y_rf), file=outF)\n",
    "print('Mean Squared Error (MSE):', metrics.mean_squared_error(y_test, y_rf), file=outF)\n",
    "print('Root Mean Squared Error (RMSE):', np.sqrt(metrics.mean_squared_error(y_test, y_rf)), file=outF)\n",
    "outF.close()\n",
    "\n",
    "print('Mean Absolute Error (MAE):', metrics.mean_absolute_error(y_test, y_rf))\n",
    "print('Mean Squared Error (MSE):', metrics.mean_squared_error(y_test, y_rf))\n",
    "print('Root Mean Squared Error (RMSE):', np.sqrt(metrics.mean_squared_error(y_test, y_rf)))\n",
    "\n",
    "x_test_dim = sc_x.inverse_transform(x_test)\n",
    "y_test_dim = sc_y.inverse_transform(y_test)\n",
    "y_rf_dim   = sc_y.inverse_transform(y_rf)\n",
    "\n",
    "plt.scatter(x_test_dim[:,1], y_test_dim[:], s=5, c='red',  marker='o', label='KAPPA')\n",
    "plt.scatter(x_test_dim[:,1], y_rf_dim[:],   s=2, c='cyan', marker='*', label='Random Forest')\n",
    "plt.title('Shear viscosity regression with RF')\n",
    "plt.ylabel(r'$\\eta$ [PaÂ·s]')\n",
    "plt.xlabel('T [K] ')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"eta_RF.pdf\", dpi=150, crop='false')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
