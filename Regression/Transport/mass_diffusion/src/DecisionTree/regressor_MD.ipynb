{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "import dask.array as da\n",
    "\n",
    "import dask.dataframe as dd\n",
    "\n",
    "from dask.diagnostics import ProgressBar\n",
    "ProgressBar().register()\n",
    "\n",
    "from dask.distributed import Client\n",
    "client = Client()  # start distributed scheduler locally.  Launch dashboard\n",
    "\n",
    "from joblib import parallel_backend\n",
    "\n",
    "# Import database\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#%time df = dd.read_csv(\"/home/lk/Public/MLA/TransportCoeffsRegression/data/TCs_air5.csv\").persist()\n",
    "#%time dataset=np.loadtxt(\"/home/lk/Public/MLA/TransportCoeffsRegression/data/TCs_air5_MD2.txt\")\n",
    "#%time dataset = pd.read_csv(\"/home/lk/Public/MLA/TransportCoeffsRegression/data/TCs_air5_MD2.txt\")\n",
    "#x = dataset[:,0:7] # T, P, x_N2, x_O2, x_NO, x_N, x_O\n",
    "#y = dataset[:,7:]  # D_cidk upper triangular matrix (Dij | j=>i)\n",
    "#x = df[:,0:7] # T, P, x_N2, x_O2, x_NO, x_N, x_O\n",
    "#y = df[:,7:]  # D_cidk upper triangular matrix (Dij | j=>i)\n",
    "#dataset.head()\n",
    "\n",
    "df.head(10)\n",
    "#import h5py\n",
    "#import xarray as xr\n",
    "import os\n",
    "import time\n",
    "#filename = os.path.join('data', 'accounts.*.csv')\n",
    "#filename\n",
    "#target = os.path.join('data', 'accounts.h5')\n",
    "#target\n",
    "df_hdf = dd.read_hdf('myh4file.h5', ' ')\n",
    "df_hdf.head()\n",
    "\n",
    "#f = h5py.File(os.path.join('.', 'myh4file.h5'), mode='r')\n",
    "\n",
    "import time\n",
    "import sys\n",
    "sys.path.insert(0, '../../../Utilities/')\n",
    "\n",
    "from plotting import newfig, savefig\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import operator\n",
    "import itertools\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import *\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "from joblib import dump, load\n",
    "import pickle\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "\n",
    "n_jobs = 1\n",
    "trial  = 1\n",
    "\n",
    "# The data is then split into training and test data\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=0.75, test_size=0.25, random_state=69)\n",
    "\n",
    "sc_x = StandardScaler()\n",
    "sc_y = StandardScaler()\n",
    "\n",
    "sc_x.fit(x_train)\n",
    "x_train = sc_x.fit_transform(x_train)\n",
    "x_test  = sc_x.fit_transform(x_test)\n",
    "\n",
    "sc_y.fit(y_train)\n",
    "y_train = sc_y.transform(y_train)\n",
    "y_test  = sc_y.transform(y_test)\n",
    "\n",
    "dump(sc_x, open('../scaler/scaler_x_MD.pkl', 'wb'))\n",
    "dump(sc_y, open('../scaler/scaler_y_MD.pkl', 'wb'))\n",
    "\n",
    "print('Training Features Shape:', x_train.shape)\n",
    "print('Training Labels Shape:', y_train.shape)\n",
    "print('Testing Features Shape:', x_test.shape)\n",
    "print('Testing Labels Shape:', y_test.shape)\n",
    "\n",
    "regr = DecisionTreeRegressor(criterion='mse',\n",
    "                             splitter='best',\n",
    "                             max_features='auto',\n",
    "                             random_state=69)\n",
    "\n",
    "regr = MultiOutputRegressor(estimator=regr)\n",
    "\n",
    "t0 = time.time()\n",
    "with parallel_backend(\"dask\"):\n",
    "    regr.fit(x_train, y_train)\n",
    "regr_fit = time.time() - t0\n",
    "print(\"Complexity and bandwidth selected and model fitted in %.6f s\" % regr_fit)\n",
    "\n",
    "t0 = time.time()\n",
    "y_regr = regr.predict(x_test)\n",
    "regr_predict = time.time() - t0\n",
    "print(\"Prediction for %d inputs in %.6f s\" % (x_test.shape[0], regr_predict))\n",
    "\n",
    "x_test_dim = sc_x.inverse_transform(x_test)\n",
    "y_test_dim = sc_y.inverse_transform(y_test)\n",
    "y_regr_dim = sc_y.inverse_transform(y_regr)\n",
    "\n",
    "plt.scatter(x_test_dim[:,0], y_test_dim[:,0], s=5, c='k', marker='o', label='KAPPA')\n",
    "plt.scatter(x_test_dim[:,0], y_regr_dim[:,0], s=5, c='r', marker='d', label='k-Nearest Neighbour')\n",
    "plt.scatter(x_test_dim[:,0], y_test_dim[:,1], s=5, c='k', marker='o', label='KAPPA')\n",
    "plt.scatter(x_test_dim[:,0], y_regr_dim[:,1], s=5, c='r', marker='d', label='k-Nearest Neighbour')\n",
    "#plt.scatter(x_test_dim[:,0], y_test_dim[:,2], s=5, c='k', marker='o', label='KAPPA')\n",
    "#plt.scatter(x_test_dim[:,0], y_regr_dim[:,2], s=5, c='r', marker='d', label='k-Nearest Neighbour')\n",
    "#plt.title('Shear viscosity regression with kNN')\n",
    "#plt.ylabel(r'$\\eta$ [PaÂ·s]')\n",
    "plt.ylabel(' ')\n",
    "plt.xlabel('T [K] ')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../pdf/regression_MD.pdf\", dpi=150, crop='false')\n",
    "plt.show()\n",
    "\n",
    "# save the model to disk\n",
    "dump(regr, '../model/model_MD.sav')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 2
}
